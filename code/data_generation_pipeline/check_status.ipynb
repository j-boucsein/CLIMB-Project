{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76367d65-918f-4bb8-b60f-b8bcb6f93192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3534e8-69ca-4cf5-9999-d1506fd91ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tail(filename, n=100, chunk_size=1024):\n",
    "    \"\"\"Read the last `n` lines of a file efficiently.\"\"\"\n",
    "    lines = []\n",
    "    buffer = ''\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        f.seek(0, 2)  # move to end of file\n",
    "        file_size = f.tell()\n",
    "        block_end = file_size\n",
    "\n",
    "        while len(lines) <= n and block_end > 0:\n",
    "            # Calculate how much to read (avoid negative seek)\n",
    "            block_start = max(0, block_end - chunk_size)\n",
    "            f.seek(block_start)\n",
    "            chunk = f.read(block_end - block_start).decode('utf-8', errors='replace')\n",
    "            buffer = chunk + buffer\n",
    "            lines = buffer.splitlines()\n",
    "            block_end -= chunk_size\n",
    "\n",
    "    return lines[-n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecacc0d0-5eea-4704-8276-3570d9f2ced0",
   "metadata": {},
   "source": [
    "## Important Paths to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ca129b-36fe-4eef-acc6-e348ebb86f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = \"/vera/u/jerbo/my_ptmp/L25n128_suite_var\"\n",
    "run_location = \"/vera/u/jerbo/TNG-arepo/run/L25n128_suite_var\"\n",
    "template_location = run_location + \"/template\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb181f7b-bdbd-4533-8812-4ef8953f58ba",
   "metadata": {},
   "source": [
    "## Check status of runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54ece36-b2e7-40f0-b251-2c76dfb6522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check status of all runs:\n",
    "completed_runs = []\n",
    "failed_runs = []\n",
    "cancelled_runs = []\n",
    "still_running = []\n",
    "pending_runs = []\n",
    "\n",
    "with open(run_location+\"/slurm_job_ids.txt\", \"r\") as file:\n",
    "    for row in file:\n",
    "        count = int(row.split()[0][:-1])\n",
    "        job_id = row.split()[-1]\n",
    "        result = subprocess.run([\"sacct\", \"-j\", f\"{job_id}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "        sbatch_output = result.stdout.strip()\n",
    "        \n",
    "        if \"FAILED\" in sbatch_output:\n",
    "            failed_runs.append(count)\n",
    "        elif \"CANCELLED\" in sbatch_output:\n",
    "            cancelled_runs.append(count)\n",
    "        elif \"RUNNING\" in sbatch_output:\n",
    "            still_running.append(count)\n",
    "        elif \"PENDING\" in sbatch_output:\n",
    "            pending_runs.append(count)\n",
    "        if not \"FAILED\" in sbatch_output and not \"PENDING\" in sbatch_output and not \"CANCELLED\" in sbatch_output and not \"RUNNING\" in sbatch_output:\n",
    "            completed_runs.append(count)\n",
    "            \n",
    "        #print(count)\n",
    "        #print(sbatch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cdc0b9-95c6-4110-9e99-ddbea161fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed runs: 61\n",
      "Failed runs: 32\n",
      "Cancelled runs: 0\n",
      "Still running: 0\n",
      "Pending runs: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Completed runs: {len(completed_runs)}\")\n",
    "print(f\"Failed runs: {len(failed_runs)}\")\n",
    "print(f\"Cancelled runs: {len(cancelled_runs)}\")\n",
    "print(f\"Still running: {len(still_running)}\")\n",
    "print(f\"Pending runs: {len(pending_runs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e3647e-cfd8-4e35-b907-d661ca94f7f3",
   "metadata": {},
   "source": [
    "## Anaylsis of failed runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e667397-d3d1-496d-b4f7-a6fd868617c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Analysis of failed runs --------------\n",
      "Parameter: Omega_m\n",
      "Failed runs:       Mean = 0.28841        std  = 0.09255\n",
      "From full grid:    Mean = 0.29551        std  = 0.10380\n",
      "Difference:       dMean = 2.5%          dstd  = 12.2%\n",
      "\n",
      "List of values:\n",
      "[0.1557829  0.31104746 0.35115538 0.42401161 0.18128417 0.19160632\n",
      " 0.26249006 0.29909306 0.19792232 0.28887779 0.20863017 0.30302319\n",
      " 0.18916954 0.28786641 0.36678391 0.31483586 0.49294396 0.32732094\n",
      " 0.13960277 0.25561588 0.33105583 0.17851445 0.30767042 0.27410585\n",
      " 0.42234436 0.41475043 0.41271069 0.17027243 0.21568755 0.42858483\n",
      " 0.23606189]\n",
      "-----------------------------\n",
      "Parameter: Omega_b\n",
      "Failed runs:       Mean = 0.05173        std  = 0.02729\n",
      "From full grid:    Mean = 0.04946        std  = 0.03044\n",
      "Difference:       dMean = 4.4%          dstd  = 11.5%\n",
      "\n",
      "List of values:\n",
      "[0.02116783 0.0235578  0.05758851 0.05755995 0.02866033 0.03784987\n",
      " 0.09190029 0.02895946 0.06400744 0.09197417 0.06391768 0.04634405\n",
      " 0.04507778 0.06036814 0.04636413 0.00197535 0.0954017  0.06992661\n",
      " 0.00351399 0.02328892 0.08332603 0.02408584 0.05669395 0.08262837\n",
      " 0.09474633 0.06866736 0.02870767 0.02072345 0.09647653 0.04231638\n",
      " 0.04585232]\n",
      "-----------------------------\n",
      "Parameter: Omega_Lambda\n",
      "Failed runs:       Mean = 0.71159        std  = 0.09255\n",
      "From full grid:    Mean = 0.70449        std  = 0.10380\n",
      "Difference:       dMean = 1.0%          dstd  = 12.2%\n",
      "\n",
      "List of values:\n",
      "[0.8442171  0.68895254 0.64884462 0.57598839 0.81871583 0.80839368\n",
      " 0.73750994 0.70090694 0.80207768 0.71112221 0.79136983 0.69697681\n",
      " 0.81083046 0.71213359 0.63321609 0.68516414 0.50705604 0.67267906\n",
      " 0.86039723 0.74438412 0.66894417 0.82148555 0.69232958 0.72589415\n",
      " 0.57765564 0.58524957 0.58728931 0.82972757 0.78431245 0.57141517\n",
      " 0.76393811]\n",
      "-----------------------------\n",
      "Parameter: Hubble_parameter\n",
      "Failed runs:       Mean = 0.71685        std  = 0.07847\n",
      "From full grid:    Mean = 0.69981        std  = 0.08745\n",
      "Difference:       dMean = 2.4%          dstd  = 11.5%\n",
      "\n",
      "List of values:\n",
      "[0.76536183 0.68099658 0.81748617 0.79093534 0.68286102 0.78316389\n",
      " 0.64510675 0.84421084 0.82330983 0.72879486 0.76977329 0.61416858\n",
      " 0.63555073 0.71772518 0.66044794 0.78423248 0.74909569 0.70093832\n",
      " 0.80917115 0.75480152 0.62389319 0.64647415 0.65345544 0.59638655\n",
      " 0.79611332 0.77498494 0.83028988 0.55854276 0.60763385 0.71063133\n",
      " 0.66593626]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "grid_csv_file_path = \"/vera/u/jerbo/code/TNG-arepo-scripts/running_sims/L25n256/grid_lhs_constrained.csv\"\n",
    "grid_csv_stats_file_path = \"/vera/u/jerbo/code/TNG-arepo-scripts/running_sims/L25n256/grid_lhs_constrained_basic_stats.csv\"\n",
    "grid_point_indices = failed_runs\n",
    "\n",
    "full_grid_stats = []\n",
    "with open(grid_csv_stats_file_path) as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader, None)\n",
    "    for i in reader:\n",
    "        full_grid_stats.append(i)\n",
    "\n",
    "with open(grid_csv_file_path, newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader, None)\n",
    "    interestingrows=[row for idx, row in enumerate(reader) if idx in grid_point_indices]\n",
    "\n",
    "for i in range(len(interestingrows)):\n",
    "    for j in range(len(interestingrows[i])):\n",
    "        interestingrows[i][j] = float(interestingrows[i][j])\n",
    "    \n",
    "interestingrows = np.array(interestingrows).T\n",
    "print(\"-------------- Analysis of failed runs --------------\")\n",
    "for i, x in enumerate(interestingrows):\n",
    "    print(\"Parameter:\", header[i])\n",
    "    print(f\"Failed runs:       Mean = {x.mean():.5f}        std  = {x.std():.5f}\")\n",
    "    print(f\"From full grid:    Mean = {float(full_grid_stats[i][2]):.5f}        std  = {float(full_grid_stats[i][3]):.5f}\")\n",
    "    \n",
    "    diff_mean_percent = abs(x.mean()-float(full_grid_stats[i][2]))/x.mean() * 100\n",
    "    diff_std_percent = abs(x.std()-float(full_grid_stats[i][3]))/x.std() * 100\n",
    "    print(f\"Difference:       dMean = {diff_mean_percent:.1f}%          dstd  = {diff_std_percent:.1f}%\")\n",
    "    print(\"\")\n",
    "    print(\"List of values:\")\n",
    "    print(x)\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cedb4d-c941-44fb-8695-330b5f921fcd",
   "metadata": {},
   "source": [
    "## Analysus of sucessful runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7e133e-36c7-42fe-98e6-5f7ef5dc6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ 0 --------------\n",
      "Finished run\n",
      "------------ 1 --------------\n",
      "Finished run\n",
      "------------ 2 --------------\n",
      "Finished run\n",
      "------------ 3 --------------\n",
      "Finished run\n",
      "------------ 4 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 5 --------------\n",
      "Finished run\n",
      "------------ 6 --------------\n",
      "Finished run\n",
      "------------ 7 --------------\n",
      "Finished run\n",
      "------------ 8 --------------\n",
      "Finished run\n",
      "------------ 9 --------------\n",
      "Finished run\n",
      "------------ 10 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 11 --------------\n",
      "Finished run\n",
      "------------ 12 --------------\n",
      "Finished run\n",
      "------------ 13 --------------\n",
      "Finished run\n",
      "------------ 14 --------------\n",
      "Finished run\n",
      "------------ 15 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 16 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 17 --------------\n",
      "Finished run\n",
      "------------ 18 --------------\n",
      "Finished run\n",
      "------------ 19 --------------\n",
      "Finished run\n",
      "------------ 20 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 21 --------------\n",
      "Finished run\n",
      "------------ 22 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 23 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 24 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 25 --------------\n",
      "Finished run\n",
      "------------ 27 --------------\n",
      "Finished run\n",
      "------------ 28 --------------\n",
      "Finished run\n",
      "------------ 29 --------------\n",
      "Finished run\n",
      "------------ 30 --------------\n",
      "Finished run\n",
      "------------ 31 --------------\n",
      "Finished run\n",
      "------------ 32 --------------\n",
      "Finished run\n",
      "------------ 33 --------------\n",
      "Finished run\n",
      "------------ 34 --------------\n",
      "Finished run\n",
      "------------ 35 --------------\n",
      "Finished run\n",
      "------------ 36 --------------\n",
      "Finished run\n",
      "------------ 37 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 38 --------------\n",
      "Finished run\n",
      "------------ 39 --------------\n",
      "Finished run\n",
      "------------ 40 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 41 --------------\n",
      "Finished run\n",
      "------------ 42 --------------\n",
      "Finished run\n",
      "------------ 43 --------------\n",
      "Finished run\n",
      "------------ 44 --------------\n",
      "Finished run\n",
      "------------ 45 --------------\n",
      "Finished run\n",
      "------------ 46 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 47 --------------\n",
      "Finished run\n",
      "------------ 48 --------------\n",
      "Finished run\n",
      "------------ 49 --------------\n",
      "Finished run\n",
      "------------ 4 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 10 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 15 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 16 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 20 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 22 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 23 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 24 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 37 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 40 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 46 --------------\n",
      "Finished run\n",
      "Finished run\n",
      "------------ 26 --------------\n",
      "Finished run\n"
     ]
    }
   ],
   "source": [
    "finished_runs = []\n",
    "restart_runs = []\n",
    "missclassified_runs = []\n",
    "\n",
    "for gp in completed_runs:\n",
    "    print(f\"------------ {gp} --------------\")\n",
    "    gp_run_location = run_location + f'/gridpoint{gp}'\n",
    "    files_in_gp_run_location = os.listdir(gp_run_location)\n",
    "    \n",
    "    if 'running_done' in files_in_gp_run_location:\n",
    "        tail_cpu_txt_file = tail(output_location + f'/gridpoint{gp}/cpu.txt', n=100)\n",
    "        last_step_row = [row for row in tail_cpu_txt_file if 'Step' in row][-1].split(\",\")\n",
    "        last_step_list = [part for part in last_step_row if 'Time' in part][0].split()\n",
    "        time = float(last_step_list[-1])\n",
    "        if np.isclose(time, 1):\n",
    "            print(\"Finished run\")\n",
    "            finished_runs.append(gp)\n",
    "        else:\n",
    "            last_cumm_time = [row for row in tail_cpu_txt_file if 'total' in row][-1].split(\",\")\n",
    "            time_needed_so_far = float(last_cumm_time[0].split()[3])/3600  # in hours\n",
    "            expected_runtime_for_rest = time_needed_so_far * (1 - time)\n",
    "            print(f\"Restart needed. Currently at Time {time}\")\n",
    "            print(f\"Expected further run time {expected_runtime_for_rest:.1f} hours\")\n",
    "            restart_runs.append(gp)\n",
    "    \n",
    "    if 'running' in files_in_gp_run_location:\n",
    "        tail_cpu_txt_file = tail(output_location + f'/gridpoint{gp}/cpu.txt', n=100)\n",
    "        last_step_row = [row for row in tail_cpu_txt_file if 'Step' in row][-1].split(\",\")\n",
    "        last_step_list = [part for part in last_step_row if 'Time' in part][0].split()\n",
    "        time = float(last_step_list[-1])\n",
    "        if np.isclose(time, 1):\n",
    "            print(\"Finished run\")\n",
    "            finished_runs.append(gp)\n",
    "        else:\n",
    "            print(\"Something went wrong in the classification with this one! Not sure what happened here...\")\n",
    "            missclassified_runs.append(gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09367bc7-12be-42dc-970e-5fac80915e30",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256b5547-4b6d-47cc-80f2-ef1f44c8e255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessful runs: 50\n",
      " -- of that finished: 50\n",
      " -- of that to restart: 0\n",
      " -- of that missclassified: 0\n",
      "Failed runs: 31\n",
      "Cancelled runs: 0\n",
      "Still running: 0\n",
      "Pending runs: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sucessful runs:\", len(set(completed_runs)))\n",
    "print(\" -- of that finished:\", len(set(finished_runs)))\n",
    "print(\" -- of that to restart:\", len(restart_runs))\n",
    "print(\" -- of that missclassified:\", len(set(missclassified_runs)))\n",
    "print(f\"Failed runs: {len(set(failed_runs))}\")\n",
    "print(f\"Cancelled runs: {len(set(cancelled_runs))}\")\n",
    "print(f\"Still running: {len(set(still_running))}\")\n",
    "print(f\"Pending runs: {len(set(pending_runs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1de2431-a928-43bf-8686-f260caf46ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49}\n",
      "--- Not finished ---\n",
      "set()\n",
      "Failed: [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 26]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(set(finished_runs))\n",
    "print(\"--- Not finished ---\")\n",
    "#for i in range(50):\n",
    "#    if i not in finished_runs:\n",
    "#        print(i)\n",
    "#print(\"--- Not finished ---\")\n",
    "print(set(restart_runs))\n",
    "print(\"Failed:\", failed_runs)\n",
    "print(missclassified_runs)\n",
    "# Runs that I manually delted the restart files from :\n",
    "# [2, 6, 10, 11, 13, 15, 19, 23, 24, 25, 27, 29, 30, 31]\n",
    "\n",
    "# 40 is done indeed\n",
    "# 45 has the peano grid error\n",
    "# 48 has the peano grid error\n",
    "# 34 also has peano grid error - but was the one I restarted because of the error! :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1209e20f-3224-450a-9465-a0885ddf99f7",
   "metadata": {},
   "source": [
    "## Restart the runs that were not completed (but sucessful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229d865-77f4-4ca8-97ba-5945d7f15055",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Dont run this carelessly\"\n",
    "# edit scrip.slurm for the reruns\n",
    "# also add the still running ones, as they will likely also need a restart once they are completed\n",
    "restart_runs = restart_runs # + still_running\n",
    "\n",
    "for gp in restart_runs:\n",
    "    run_gridpoint_path = run_location + f\"/gridpoint{gp}\"\n",
    "    \n",
    "    path_to_slurm_script = run_gridpoint_path + \"/script.slurm\"\n",
    "    \n",
    "    file_content = []\n",
    "    with open(path_to_slurm_script, \"r\", encoding=\"utf-8\") as file:\n",
    "        for row in file:\n",
    "            if \"srun ./Arepo_L25n128 param_L25n128.txt\" in row:\n",
    "                row = f\"srun ./Arepo_L25n128 param_L25n128.txt 1\\n\"\n",
    "            file_content.append(row)\n",
    "\n",
    "    with open(path_to_slurm_script, \"w\") as file:\n",
    "        for row in file_content:\n",
    "            file.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd0bc2-9a5a-49fa-8e76-1723532f6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Dont run this carelessly\"\n",
    "# actually submit the sbatch jobs for the reruns\n",
    "for gp in restart_runs:\n",
    "    run_gridpoint_path = run_location + f\"/gridpoint{gp}\"\n",
    "    \n",
    "    os.chdir(run_gridpoint_path)\n",
    "    \n",
    "    # submit the job script to slurm\n",
    "    slurm_script = \"script.slurm\"\n",
    "    result = subprocess.run([\"sbatch\", slurm_script], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    sbatch_output = result.stdout.strip()\n",
    "    \n",
    "    with open(run_location+\"/slurm_job_ids.txt\", \"a\") as myfile:\n",
    "        myfile.write(f\"{gp}: {sbatch_output}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc405f30-a577-4226-ad57-f810c5392dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
