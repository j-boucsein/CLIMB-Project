{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe3ed4-14d3-4a6a-9fa7-67579d9599d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8f2a7-ef98-47e0-aed6-6ee8b9b7e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = \"/vera/u/jerbo/my_ptmp/L25n128_suite\"\n",
    "run_location = \"/vera/u/jerbo/TNG-arepo/run/L25n128_suite\"\n",
    "template_location = run_location + \"/template\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2048470-4be7-4fe6-853b-4a8f78b5a0f7",
   "metadata": {},
   "source": [
    "os.mkdir(output_location + \"/test\")\n",
    "os.chdir(output_location)\n",
    "os.getcwd()\n",
    "print(os.listdir())\n",
    "os.rmdir(output_location + \"/test\")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e78cb3-c5a8-4c3f-a5d0-5e31bb511a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"This cell is here to stop an accidental run all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afafa5-6ee1-4f27-8462-be650352e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Don't run this again\"\n",
    "\n",
    "######################## read grid file ###########################\n",
    "cosmo_parameters = []\n",
    "\n",
    "header = True\n",
    "with open('grid_lhs_constrained.csv', newline='') as f:\n",
    "    file = csv.reader(f, delimiter=',')\n",
    "    for row in file:\n",
    "        if header:\n",
    "            header = False\n",
    "            continue\n",
    "        cosmo_parameters.append([float(i) for i in row])\n",
    "        \n",
    "# cosmo_parameters = cosmo_parameters[:10] # ATTETION: ONLY FOR TESTING!! remove this for finished script\n",
    "\n",
    "##################### loop over grid points ######################\n",
    "\n",
    "for counter, (Omega_m, Omega_b, Omega_L, hubble_par) in enumerate(cosmo_parameters):\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Grid Point Nr.\", counter)\n",
    "    print(f\"Omega_m = {Omega_m:.3f}, Omega_b = {Omega_b:.3f}, Omega_L = {Omega_L:.3f}, h = {hubble_par:.3f}\")\n",
    "    \n",
    "    # create output directory\n",
    "    output_gridpoint = output_location+f\"/gridpoint{counter}\"\n",
    "    os.mkdir(output_gridpoint)\n",
    "    \n",
    "    # create run directory\n",
    "    run_gridpoint = run_location+f\"/gridpoint{counter}\"\n",
    "    os.mkdir(run_gridpoint)\n",
    "    \n",
    "    # copy template to run directory\n",
    "    cmd = f\"cp -r {template_location}/* {run_gridpoint}\"\n",
    "    os.system(cmd)\n",
    "    \n",
    "    # check if all expected files are there\n",
    "    visible_files_template = [file for file in os.listdir(template_location) if not file.startswith('.')]\n",
    "    visible_files_run = [file for file in os.listdir(run_gridpoint) if not file.startswith('.')]\n",
    "    if not visible_files_template == visible_files_run:\n",
    "        print(\"Error! -> Copying template failed\")\n",
    "        print(\"Skipping this gridpoint ...\")\n",
    "        continue\n",
    "    \n",
    "    # edit param.txt to match gridpoint values\n",
    "    path_to_param_file = run_gridpoint + \"/param_L25n128.txt\"\n",
    "    \n",
    "    file_content = []\n",
    "    with open(path_to_param_file, \"r\") as file:\n",
    "        for row in file:\n",
    "            if \"Omega0\" in row:\n",
    "                row = f\"Omega0\t              {Omega_m:.4f}\\n\"\n",
    "            if \"OmegaLambda\" in row:\n",
    "                row = f\"OmegaLambda           {Omega_L:.4f}\\n\"\n",
    "            if \"OmegaBaryon\" in row:\n",
    "                row = f\"OmegaBaryon           {Omega_b:.4f}\\n\"\n",
    "            if \"HubbleParam\" in row:\n",
    "                row = f\"HubbleParam           {hubble_par:.4f}\\n\"\n",
    "            if \"OutputDir\" in row:\n",
    "                row = f\"OutputDir           {output_gridpoint}\\n\"\n",
    "            file_content.append(row)\n",
    "\n",
    "    with open(path_to_param_file, \"w\") as file:\n",
    "        for row in file_content:\n",
    "            file.write(row)\n",
    "            \n",
    "    # check if the edits have worked in \n",
    "    error = False\n",
    "    with open(path_to_param_file, \"r\") as file:\n",
    "        for row in file:\n",
    "            if \"Omega0\" in row:\n",
    "                if not row.split()[-1] == f\"{Omega_m:.4f}\":\n",
    "                    print(f\"Error! -> Omega0 not correctly set in {path_to_param_file}\")\n",
    "                    error = True\n",
    "            if \"OmegaLambda\" in row:\n",
    "                if not row.split()[-1] == f\"{Omega_L:.4f}\":\n",
    "                    print(f\"Error! -> OmegaL not correctly set in {path_to_param_file}\")\n",
    "                    error = True\n",
    "            if \"OmegaBaryon\" in row:\n",
    "                if not row.split()[-1] == f\"{Omega_b:.4f}\":\n",
    "                    print(f\"Error! -> OmegaB not correctly set in {path_to_param_file}\")\n",
    "                    error = True\n",
    "            if \"HubbleParam\" in row:\n",
    "                if not row.split()[-1] == f\"{hubble_par:.4f}\":\n",
    "                    print(f\"Error! -> HubblePar not correctly set in {path_to_param_file}\")\n",
    "                    error = True\n",
    "            if \"OutputDir\" in row:\n",
    "                if not row.split()[-1] == output_gridpoint:\n",
    "                    print(f\"Error! -> OutputDir not correctly set in {path_to_param_file}\")\n",
    "                    error = True\n",
    "    \n",
    "    if error:\n",
    "        print(\"Skipping this gridpoint ...\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"{path_to_param_file} was edited successfully!\")\n",
    "            \n",
    "    # edit param_muscic.txt to match gridpoint values\n",
    "    path_to_param_music_file = run_gridpoint + \"/param_music.txt\"\n",
    "    \n",
    "    file_content = []\n",
    "    with open(path_to_param_music_file, \"r\") as file:\n",
    "        for row in file:\n",
    "            if \"Omega_m\" in row:\n",
    "                row = f\"Omega_m           = {Omega_m:.4f}\\n\"\n",
    "            if \"Omega_L\" in row:\n",
    "                row = f\"Omega_L           = {Omega_L:.4f}\\n\"\n",
    "            if \"Omega_b\" in row:\n",
    "                row = f\"Omega_b           = {Omega_b:.4f}\\n\"\n",
    "            if \"H0\" in row:\n",
    "                row = f\"H0                = {100*hubble_par:.2f}\\n\"\n",
    "            file_content.append(row)\n",
    "\n",
    "    with open(path_to_param_music_file, \"w\") as file:\n",
    "        for row in file_content:\n",
    "            file.write(row)\n",
    "            \n",
    "    # check if the edits have worked\n",
    "    error = False\n",
    "    with open(path_to_param_music_file, \"r\") as file:\n",
    "        for row in file:\n",
    "            if \"Omega_m\" in row:\n",
    "                if not row.split()[-1] == f\"{Omega_m:.4f}\":\n",
    "                    print(f\"Error! -> Omega0 not correctly set in {path_to_param_music_file}\")\n",
    "                    error = True\n",
    "            if \"Omega_L\" in row:\n",
    "                if not row.split()[-1] == f\"{Omega_L:.4f}\":\n",
    "                    print(f\"Error! -> OmegaL not correctly set in {path_to_param_music_file}\")\n",
    "                    error = True\n",
    "            if \"Omega_b\" in row:\n",
    "                if not row.split()[-1] == f\"{Omega_b:.4f}\":\n",
    "                    print(f\"Error! -> OmegaB not correctly set in {path_to_param_music_file}\")\n",
    "                    error = True\n",
    "            if \"H0\" in row:\n",
    "                if not row.split()[-1] == f\"{100*hubble_par:.2f}\":\n",
    "                    print(f\"Error! -> HubblePar not correctly set in {path_to_param_music_file}\")\n",
    "                    error = True\n",
    "    \n",
    "    if error:\n",
    "        print(\"Skipping this gridpoint ...\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"{path_to_param_music_file} was edited successfully!\")\n",
    "        \n",
    "    # run custom_create.py to make the initial conditions\n",
    "    os.chdir(run_gridpoint)\n",
    "    cmd = f\"python3 custom_create.py {run_gridpoint}\"\n",
    "    os.system(cmd)\n",
    "    \n",
    "    # check if ics.hdf5 file exists\n",
    "    files_in_run_dir = os.listdir(run_gridpoint)\n",
    "    if \"ics.hdf5\" in files_in_run_dir:\n",
    "        print(\"ICs were sucessfully created!\")\n",
    "    else:\n",
    "        print(\"Error! -> IC creation failed\")\n",
    "        print(\"Skipping this gridpoint ...\")\n",
    "        continue\n",
    "    \n",
    "    # edit name in script.slurm\n",
    "    path_to_slurm_script = run_gridpoint + \"/script.slurm\"\n",
    "    \n",
    "    file_content = []\n",
    "    with open(path_to_slurm_script, \"r\", encoding=\"utf-8\") as file:\n",
    "        for row in file:\n",
    "            if \"SBATCH -J\" in row:\n",
    "                row = f\"#SBATCH -J CLIMB-GP-{counter}\\n\"\n",
    "            file_content.append(row)\n",
    "\n",
    "    with open(path_to_slurm_script, \"w\") as file:\n",
    "        for row in file_content:\n",
    "            file.write(row)\n",
    "            \n",
    "    # submit the job script to slurm\n",
    "    slurm_script = \"script.slurm\"\n",
    "    result = subprocess.run([\"sbatch\", slurm_script], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    sbatch_output = result.stdout.strip()\n",
    "    \n",
    "    with open(run_location+\"/slurm_job_ids.txt\", \"a\") as myfile:\n",
    "        myfile.write(f\"{counter}: {sbatch_output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4ee5d-3bf9-4d68-afbd-7ac4b0b94a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which of the jobs are still pending\n",
    "restart_job_ids = []\n",
    "with open(run_location+\"/slurm_job_ids.txt\", \"r\") as file:\n",
    "    for row in file:\n",
    "        count = int(row.split()[0][:-1])\n",
    "        job_id = row.split()[-1]\n",
    "        print(\"GridPoint\", count)\n",
    "        result = subprocess.run([\"sacct\", \"-j\", f\"{job_id}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "        sbatch_output = result.stdout.strip()\n",
    "        if \"PENDING\" in sbatch_output:\n",
    "            print(sbatch_output)\n",
    "            restart_job_ids.append([count, job_id])\n",
    "        print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8da57-c204-4406-a605-4d166bc7a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(restart_job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91667be-5467-4c0f-8793-b948d2ad2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancle the pending jobs\n",
    "for gp, job_id in restart_job_ids:\n",
    "    print(gp, job_id)\n",
    "    os.system(f\"scancel {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e3c9f-82cf-4c0e-9c5b-299e9d40cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"don't run this\"\n",
    "# change the number of nodes and allowed time for the previously cancled jobs\n",
    "for gp, job_id in restart_job_ids:\n",
    "    run_gridpoint_path = run_location + f\"/gridpoint{gp}\"\n",
    "    \n",
    "    path_to_slurm_script = run_gridpoint_path + \"/script.slurm\"\n",
    "    \n",
    "    file_content = []\n",
    "    with open(path_to_slurm_script, \"r\", encoding=\"utf-8\") as file:\n",
    "        for row in file:\n",
    "            if \"SBATCH --nodes=\" in row:\n",
    "                row = f\"#SBATCH --nodes=1\\n\"\n",
    "            file_content.append(row)\n",
    "\n",
    "    with open(path_to_slurm_script, \"w\") as file:\n",
    "        for row in file_content:\n",
    "            file.write(row)\n",
    "            \n",
    "    path_to_param_file = run_gridpoint_path + \"/param_L25n128.txt\"\n",
    "    \n",
    "    file_content = []\n",
    "    with open(path_to_param_file, \"r\") as file:\n",
    "        for row in file:\n",
    "            if \"TimeLimitCPU\" in row:\n",
    "                row = f\"TimeLimitCPU           36000\\n\"\n",
    "            file_content.append(row)\n",
    "\n",
    "    with open(path_to_param_file, \"w\") as file:\n",
    "        for row in file_content:\n",
    "            file.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb30bb8-7ad3-4fc5-80f5-fe8dfa09a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Don't run this again either\"\n",
    "# resubmit the jobs\n",
    "for gp, job_id in restart_job_ids:\n",
    "    run_gridpoint_path = run_location + f\"/gridpoint{gp}\"\n",
    "    os.chdir(run_gridpoint_path)\n",
    "    \n",
    "    slurm_script = \"script.slurm\"\n",
    "    result = subprocess.run([\"sbatch\", slurm_script], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    sbatch_output = result.stdout.strip()\n",
    "    \n",
    "    with open(run_location+\"/slurm_job_ids.txt\", \"a\") as myfile:\n",
    "        myfile.write(f\"{gp}: {sbatch_output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82164696-fc8a-4f72-a8f6-bdf26d067751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check up on status\n",
    "successfull_runs = []\n",
    "with open(run_location+\"/slurm_job_ids.txt\", \"r\") as file:\n",
    "    for row in file:\n",
    "        count = int(row.split()[0][:-1])\n",
    "        job_id = row.split()[-1]\n",
    "        print(\"GridPoint\", count)\n",
    "        result = subprocess.run([\"sacct\", \"-j\", f\"{job_id}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "        sbatch_output = result.stdout.strip()\n",
    "        if not \"FAILED\" in sbatch_output and not \"PENDING\" in sbatch_output and not \"CANCELLED\" in sbatch_output and not \"RUNNING\" in sbatch_output:\n",
    "            print(sbatch_output)\n",
    "            successfull_runs.append(count)\n",
    "        print(\"---------------------------------\")\n",
    "print(successfull_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0786b51-7098-422d-b6bd-09357fc8bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check status of all runs:\n",
    "completed_runs = []\n",
    "failed_runs = []\n",
    "cancelled_runs = []\n",
    "still_running = []\n",
    "pending_runs = []\n",
    "\n",
    "with open(run_location+\"/slurm_job_ids.txt\", \"r\") as file:\n",
    "    for row in file:\n",
    "        count = int(row.split()[0][:-1])\n",
    "        job_id = row.split()[-1]\n",
    "        print(\"GridPoint\", count)\n",
    "        result = subprocess.run([\"sacct\", \"-j\", f\"{job_id}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "        sbatch_output = result.stdout.strip()\n",
    "        \n",
    "        if \"FAILED\" in sbatch_output:\n",
    "            print(\"Failed\")\n",
    "            print(sbatch_output)\n",
    "            failed_runs.append(count)\n",
    "        elif \"CANCELLED\" in sbatch_output:\n",
    "            print(\"Cancelled\")\n",
    "            print(sbatch_output)\n",
    "            cancelled_runs.append(count)\n",
    "        elif \"RUNNING\" in sbatch_output:\n",
    "            print(\"running\")\n",
    "            print(sbatch_output)\n",
    "            still_running.append(count)\n",
    "        elif \"PENDING\" in sbatch_output:\n",
    "            print(\"pending\")\n",
    "            print(sbatch_output)\n",
    "            pending_runs.append(count)\n",
    "        if not \"FAILED\" in sbatch_output and not \"PENDING\" in sbatch_output and not \"CANCELLED\" in sbatch_output and not \"RUNNING\" in sbatch_output:\n",
    "            print(\"success\")\n",
    "            print(sbatch_output)\n",
    "            completed_runs.append(count)\n",
    "        print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7c2e3-9f5f-47a3-9876-166f3dc0414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Completed runs: {len(completed_runs)}\")\n",
    "print(f\"Failed runs: {len(failed_runs)}\")\n",
    "print(f\"Cancelled runs: {len(cancelled_runs)}\")\n",
    "print(f\"Still running: {len(still_running)}\")\n",
    "print(f\"Pending runs: {len(pending_runs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3fed3-a7fa-4c66-b0aa-20428bac3b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "grid_csv_file_path = \"/vera/u/jerbo/code/TNG-arepo-scripts/grid_lhs_constrained.csv\"\n",
    "grid_point_indices = [i for i in failed_runs]\n",
    "\n",
    "with open(grid_csv_file_path, newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader, None)\n",
    "    interestingrows=[row for idx, row in enumerate(reader) if idx in grid_point_indices]\n",
    "\n",
    "for i in range(len(interestingrows)):\n",
    "    for j in range(len(interestingrows[i])):\n",
    "        interestingrows[i][j] = float(interestingrows[i][j])\n",
    "    \n",
    "interestingrows = np.array(interestingrows).T\n",
    "print(\"-------------- Analysis of failed runs --------------\")\n",
    "for i, x in enumerate(interestingrows):\n",
    "    print(\"Parameter:\", header[i])\n",
    "    print(f\"Mean = {x.mean():.5f}\")\n",
    "    print(f\"std  = {x.std():.5f}\")\n",
    "    print(\"\")\n",
    "    print(\"List of values:\")\n",
    "    print(x)\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87720d4-94c4-4a4f-922c-adc3f116cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Dont run this again\"\n",
    "for gp in failed_runs:\n",
    "    run_gridpoint_path = run_location + f\"/gridpoint{gp}\"\n",
    "    \n",
    "    path_to_slurm_script = run_gridpoint_path + \"/script.slurm\"\n",
    "    \n",
    "    file_content = []\n",
    "    with open(path_to_slurm_script, \"r\", encoding=\"utf-8\") as file:\n",
    "        for row in file:\n",
    "            if \"SBATCH --nodes=\" in row:\n",
    "                row = f\"#SBATCH --nodes=1\\n\"\n",
    "            file_content.append(row)\n",
    "\n",
    "    with open(path_to_slurm_script, \"w\") as file:\n",
    "        for row in file_content:\n",
    "            file.write(row)\n",
    "            \n",
    "    path_to_param_file = run_gridpoint_path + \"/param_L25n128.txt\"\n",
    "    \n",
    "    file_content = []\n",
    "    with open(path_to_param_file, \"r\") as file:\n",
    "        for row in file:\n",
    "            if \"TimeLimitCPU\" in row:\n",
    "                row = f\"TimeLimitCPU           36000\\n\"\n",
    "            file_content.append(row)\n",
    "\n",
    "    with open(path_to_param_file, \"w\") as file:\n",
    "        for row in file_content:\n",
    "            file.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c170a9d-9bd8-4644-b4b1-612ec2803c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False\n",
    "#os.chdir(\"/vera/ptmp/gc/jerbo/babysitter_script_test_playground\")\n",
    "#assert os.getcwd() == \"/vera/ptmp/gc/jerbo/babysitter_script_test_playground\"\n",
    "os.system(\"rm -rf /vera/ptmp/gc/jerbo/babysitter_script_test_playground/test_folder/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae688e-df84-410c-9814-be1db33879f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False\n",
    "for gp in failed_runs:\n",
    "    out_gridpoint_path = output_location + f\"/gridpoint{gp}\"\n",
    "    cmd = f\"rm -rf {out_gridpoint_path}/*\"\n",
    "    print(cmd)\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17608ceb-35af-4696-b530-03265f02ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Dont run this again\"\n",
    "for gp in failed_runs:\n",
    "    run_gridpoint_path = run_location + f\"/gridpoint{gp}\"\n",
    "    os.chdir(run_gridpoint_path)\n",
    "    \n",
    "    slurm_script = \"script.slurm\"\n",
    "    result = subprocess.run([\"sbatch\", slurm_script], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    sbatch_output = result.stdout.strip()\n",
    "    \n",
    "    with open(run_location+\"/slurm_job_ids.txt\", \"a\") as myfile:\n",
    "        myfile.write(f\"{gp}: {sbatch_output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f9301-e43e-400c-82bd-98adb057addb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
